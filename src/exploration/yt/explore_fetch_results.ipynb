{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lucyfarnik/miniforge3/envs/y3_ads/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/var/folders/4c/w2fyysz50_j_234jdvb_c9wr0000gn/T/ipykernel_99195/815062686.py:5: DtypeWarning: Columns (6) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv('../../../data/yt_data.csv')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>username</th>\n",
       "      <th>date</th>\n",
       "      <th>country</th>\n",
       "      <th>likes</th>\n",
       "      <th>n_children</th>\n",
       "      <th>title</th>\n",
       "      <th>platform</th>\n",
       "      <th>meta</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ugw9_y5-TI9gK34R_7Z4AaABAg</td>\n",
       "      <td>나도 사용해 봤는데 초기단계라서 그런지 오답을 말해주고 틀린 정보를 말해주는 경우도...</td>\n",
       "      <td>짱부자</td>\n",
       "      <td>2023-03-28T18:41:27Z</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>GPT4 출시! 만능 AI와 글/사진/영상으로 대화하기. 뜨거운 AI 경쟁 비하인드...</td>\n",
       "      <td>youtube</td>\n",
       "      <td>{'vid_id': 'fIWpPnMW_0A', 'user_id': 'UCctowlf...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>UgxbDHn-wWEinu1lVDZ4AaABAg</td>\n",
       "      <td>감사합니다.</td>\n",
       "      <td>둥근달</td>\n",
       "      <td>2023-03-28T16:15:19Z</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>GPT4 출시! 만능 AI와 글/사진/영상으로 대화하기. 뜨거운 AI 경쟁 비하인드...</td>\n",
       "      <td>youtube</td>\n",
       "      <td>{'vid_id': 'fIWpPnMW_0A', 'user_id': 'UCaFIABm...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>UgwA0C3c6Wrj80iqCpR4AaABAg</td>\n",
       "      <td>얼굴이쁜 피부미인이 설명하시니 듣기좋구 보기좋아요  넘 감사해요 주식투자로 중요한정...</td>\n",
       "      <td>둥근달</td>\n",
       "      <td>2023-03-28T16:14:56Z</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>GPT4 출시! 만능 AI와 글/사진/영상으로 대화하기. 뜨거운 AI 경쟁 비하인드...</td>\n",
       "      <td>youtube</td>\n",
       "      <td>{'vid_id': 'fIWpPnMW_0A', 'user_id': 'UCaFIABm...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>UgzT6FJSnUMjorbg_dF4AaABAg</td>\n",
       "      <td>영상 감사드립니다. 4버전 유료 결재해서 사용하고 있어요. 타로업을 하고 있는데, ...</td>\n",
       "      <td>청포도타로</td>\n",
       "      <td>2023-03-28T14:15:02Z</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>GPT4 출시! 만능 AI와 글/사진/영상으로 대화하기. 뜨거운 AI 경쟁 비하인드...</td>\n",
       "      <td>youtube</td>\n",
       "      <td>{'vid_id': 'fIWpPnMW_0A', 'user_id': 'UCQnTg3v...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>UgwO6RKpWu0HGGMpOdl4AaABAg</td>\n",
       "      <td>Al 비하인드 스토리 진지한내용\\n너무  놀랍고  대단합니다\\n내미님 최신정보\\n감...</td>\n",
       "      <td>패션줌마</td>\n",
       "      <td>2023-03-28T13:30:51Z</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>GPT4 출시! 만능 AI와 글/사진/영상으로 대화하기. 뜨거운 AI 경쟁 비하인드...</td>\n",
       "      <td>youtube</td>\n",
       "      <td>{'vid_id': 'fIWpPnMW_0A', 'user_id': 'UC31322R...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           id  \\\n",
       "0  Ugw9_y5-TI9gK34R_7Z4AaABAg   \n",
       "1  UgxbDHn-wWEinu1lVDZ4AaABAg   \n",
       "2  UgwA0C3c6Wrj80iqCpR4AaABAg   \n",
       "3  UgzT6FJSnUMjorbg_dF4AaABAg   \n",
       "4  UgwO6RKpWu0HGGMpOdl4AaABAg   \n",
       "\n",
       "                                                text username  \\\n",
       "0  나도 사용해 봤는데 초기단계라서 그런지 오답을 말해주고 틀린 정보를 말해주는 경우도...      짱부자   \n",
       "1                                             감사합니다.      둥근달   \n",
       "2  얼굴이쁜 피부미인이 설명하시니 듣기좋구 보기좋아요  넘 감사해요 주식투자로 중요한정...      둥근달   \n",
       "3  영상 감사드립니다. 4버전 유료 결재해서 사용하고 있어요. 타로업을 하고 있는데, ...    청포도타로   \n",
       "4  Al 비하인드 스토리 진지한내용\\n너무  놀랍고  대단합니다\\n내미님 최신정보\\n감...     패션줌마   \n",
       "\n",
       "                   date country  likes n_children  \\\n",
       "0  2023-03-28T18:41:27Z     NaN    0.0        1.0   \n",
       "1  2023-03-28T16:15:19Z     NaN    0.0        0.0   \n",
       "2  2023-03-28T16:14:56Z     NaN    0.0        0.0   \n",
       "3  2023-03-28T14:15:02Z     NaN    0.0        0.0   \n",
       "4  2023-03-28T13:30:51Z     NaN    1.0        0.0   \n",
       "\n",
       "                                               title platform  \\\n",
       "0  GPT4 출시! 만능 AI와 글/사진/영상으로 대화하기. 뜨거운 AI 경쟁 비하인드...  youtube   \n",
       "1  GPT4 출시! 만능 AI와 글/사진/영상으로 대화하기. 뜨거운 AI 경쟁 비하인드...  youtube   \n",
       "2  GPT4 출시! 만능 AI와 글/사진/영상으로 대화하기. 뜨거운 AI 경쟁 비하인드...  youtube   \n",
       "3  GPT4 출시! 만능 AI와 글/사진/영상으로 대화하기. 뜨거운 AI 경쟁 비하인드...  youtube   \n",
       "4  GPT4 출시! 만능 AI와 글/사진/영상으로 대화하기. 뜨거운 AI 경쟁 비하인드...  youtube   \n",
       "\n",
       "                                                meta  \n",
       "0  {'vid_id': 'fIWpPnMW_0A', 'user_id': 'UCctowlf...  \n",
       "1  {'vid_id': 'fIWpPnMW_0A', 'user_id': 'UCaFIABm...  \n",
       "2  {'vid_id': 'fIWpPnMW_0A', 'user_id': 'UCaFIABm...  \n",
       "3  {'vid_id': 'fIWpPnMW_0A', 'user_id': 'UCQnTg3v...  \n",
       "4  {'vid_id': 'fIWpPnMW_0A', 'user_id': 'UC31322R...  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import transformers\n",
    "import math\n",
    "\n",
    "df = pd.read_csv('../../../data/yt_data.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'338,515 comments in total'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f\"{df.shape[0]:,} comments in total\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'6.1% have country locations'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f\"{100 * df['country'].notnull().sum() / df.shape[0]:.1f}% have country locations\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"There's 156 different countries\""
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f\"There's {len(set(df[df['country'].notnull()]['country'].to_list()))} different countries\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add lang column\n",
    "df['lang'] = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "text input must of type `str` (single example), `List[str]` (batch or single pretokenized example) or `List[List[str]]` (batch of pretokenized examples).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 7\u001b[0m\n\u001b[1;32m      5\u001b[0m batch \u001b[39m=\u001b[39m df[batch_size\u001b[39m*\u001b[39mbatch_i : batch_size\u001b[39m*\u001b[39m(batch_i\u001b[39m+\u001b[39m\u001b[39m1\u001b[39m)]\n\u001b[1;32m      6\u001b[0m batch_texts \u001b[39m=\u001b[39m df[\u001b[39m'\u001b[39m\u001b[39mtext\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mto_list()\n\u001b[0;32m----> 7\u001b[0m langs \u001b[39m=\u001b[39m lang_cls(batch_texts)\n\u001b[1;32m      8\u001b[0m \u001b[39mfor\u001b[39;00m i, lang \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(langs):\n\u001b[1;32m      9\u001b[0m   df\u001b[39m.\u001b[39mat[batch_size\u001b[39m*\u001b[39mbatch_i \u001b[39m+\u001b[39m i, \u001b[39m'\u001b[39m\u001b[39mlang\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m lang[\u001b[39m'\u001b[39m\u001b[39mlabel\u001b[39m\u001b[39m'\u001b[39m]\n",
      "File \u001b[0;32m~/miniforge3/envs/y3_ads/lib/python3.11/site-packages/transformers/pipelines/text_classification.py:155\u001b[0m, in \u001b[0;36mTextClassificationPipeline.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    121\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m    122\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    123\u001b[0m \u001b[39m    Classify the text(s) given as inputs.\u001b[39;00m\n\u001b[1;32m    124\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    153\u001b[0m \u001b[39m        If `top_k` is used, one such dictionary is returned per label.\u001b[39;00m\n\u001b[1;32m    154\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 155\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m\u001b[39m__call__\u001b[39;49m(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    156\u001b[0m     \u001b[39m# TODO try and retrieve it in a nicer way from _sanitize_parameters.\u001b[39;00m\n\u001b[1;32m    157\u001b[0m     _legacy \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mtop_k\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m kwargs\n",
      "File \u001b[0;32m~/miniforge3/envs/y3_ads/lib/python3.11/site-packages/transformers/pipelines/base.py:1090\u001b[0m, in \u001b[0;36mPipeline.__call__\u001b[0;34m(self, inputs, num_workers, batch_size, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1086\u001b[0m \u001b[39mif\u001b[39;00m can_use_iterator:\n\u001b[1;32m   1087\u001b[0m     final_iterator \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_iterator(\n\u001b[1;32m   1088\u001b[0m         inputs, num_workers, batch_size, preprocess_params, forward_params, postprocess_params\n\u001b[1;32m   1089\u001b[0m     )\n\u001b[0;32m-> 1090\u001b[0m     outputs \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39;49m(final_iterator)\n\u001b[1;32m   1091\u001b[0m     \u001b[39mreturn\u001b[39;00m outputs\n\u001b[1;32m   1092\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniforge3/envs/y3_ads/lib/python3.11/site-packages/transformers/pipelines/pt_utils.py:124\u001b[0m, in \u001b[0;36mPipelineIterator.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    121\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mloader_batch_item()\n\u001b[1;32m    123\u001b[0m \u001b[39m# We're out of items within a batch\u001b[39;00m\n\u001b[0;32m--> 124\u001b[0m item \u001b[39m=\u001b[39m \u001b[39mnext\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49miterator)\n\u001b[1;32m    125\u001b[0m processed \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39minfer(item, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mparams)\n\u001b[1;32m    126\u001b[0m \u001b[39m# We now have a batch of \"inferred things\".\u001b[39;00m\n",
      "File \u001b[0;32m~/miniforge3/envs/y3_ads/lib/python3.11/site-packages/transformers/pipelines/pt_utils.py:124\u001b[0m, in \u001b[0;36mPipelineIterator.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    121\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mloader_batch_item()\n\u001b[1;32m    123\u001b[0m \u001b[39m# We're out of items within a batch\u001b[39;00m\n\u001b[0;32m--> 124\u001b[0m item \u001b[39m=\u001b[39m \u001b[39mnext\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49miterator)\n\u001b[1;32m    125\u001b[0m processed \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39minfer(item, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mparams)\n\u001b[1;32m    126\u001b[0m \u001b[39m# We now have a batch of \"inferred things\".\u001b[39;00m\n",
      "File \u001b[0;32m~/miniforge3/envs/y3_ads/lib/python3.11/site-packages/torch/utils/data/dataloader.py:628\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    625\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sampler_iter \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    626\u001b[0m     \u001b[39m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    627\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reset()  \u001b[39m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 628\u001b[0m data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_next_data()\n\u001b[1;32m    629\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m    630\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset_kind \u001b[39m==\u001b[39m _DatasetKind\u001b[39m.\u001b[39mIterable \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    631\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    632\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m>\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m~/miniforge3/envs/y3_ads/lib/python3.11/site-packages/torch/utils/data/dataloader.py:671\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    669\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_next_data\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    670\u001b[0m     index \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_next_index()  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 671\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dataset_fetcher\u001b[39m.\u001b[39;49mfetch(index)  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    672\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory:\n\u001b[1;32m    673\u001b[0m         data \u001b[39m=\u001b[39m _utils\u001b[39m.\u001b[39mpin_memory\u001b[39m.\u001b[39mpin_memory(data, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[0;32m~/miniforge3/envs/y3_ads/lib/python3.11/site-packages/torch/utils/data/_utils/fetch.py:58\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     56\u001b[0m         data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset\u001b[39m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     57\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m---> 58\u001b[0m         data \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdataset[idx] \u001b[39mfor\u001b[39;49;00m idx \u001b[39min\u001b[39;49;00m possibly_batched_index]\n\u001b[1;32m     59\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     60\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m~/miniforge3/envs/y3_ads/lib/python3.11/site-packages/torch/utils/data/_utils/fetch.py:58\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     56\u001b[0m         data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset\u001b[39m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     57\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m---> 58\u001b[0m         data \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdataset[idx] \u001b[39mfor\u001b[39;00m idx \u001b[39min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     59\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     60\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m~/miniforge3/envs/y3_ads/lib/python3.11/site-packages/transformers/pipelines/pt_utils.py:19\u001b[0m, in \u001b[0;36mPipelineDataset.__getitem__\u001b[0;34m(self, i)\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__getitem__\u001b[39m(\u001b[39mself\u001b[39m, i):\n\u001b[1;32m     18\u001b[0m     item \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[i]\n\u001b[0;32m---> 19\u001b[0m     processed \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mprocess(item, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mparams)\n\u001b[1;32m     20\u001b[0m     \u001b[39mreturn\u001b[39;00m processed\n",
      "File \u001b[0;32m~/miniforge3/envs/y3_ads/lib/python3.11/site-packages/transformers/pipelines/text_classification.py:179\u001b[0m, in \u001b[0;36mTextClassificationPipeline.preprocess\u001b[0;34m(self, inputs, **tokenizer_kwargs)\u001b[0m\n\u001b[1;32m    173\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(inputs, \u001b[39mlist\u001b[39m):\n\u001b[1;32m    174\u001b[0m     \u001b[39m# This is likely an invalid usage of the pipeline attempting to pass text pairs.\u001b[39;00m\n\u001b[1;32m    175\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    176\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mThe pipeline received invalid inputs, if you are trying to send text pairs, you can try to send a\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    177\u001b[0m         \u001b[39m'\u001b[39m\u001b[39m dictionary `\u001b[39m\u001b[39m{\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mtext\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m: \u001b[39m\u001b[39m\"\u001b[39m\u001b[39mMy text\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m, \u001b[39m\u001b[39m\"\u001b[39m\u001b[39mtext_pair\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m: \u001b[39m\u001b[39m\"\u001b[39m\u001b[39mMy pair\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m}` in order to send a text pair.\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m    178\u001b[0m     )\n\u001b[0;32m--> 179\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtokenizer(inputs, return_tensors\u001b[39m=\u001b[39;49mreturn_tensors, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mtokenizer_kwargs)\n",
      "File \u001b[0;32m~/miniforge3/envs/y3_ads/lib/python3.11/site-packages/transformers/tokenization_utils_base.py:2530\u001b[0m, in \u001b[0;36mPreTrainedTokenizerBase.__call__\u001b[0;34m(self, text, text_pair, text_target, text_pair_target, add_special_tokens, padding, truncation, max_length, stride, is_split_into_words, pad_to_multiple_of, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, **kwargs)\u001b[0m\n\u001b[1;32m   2528\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_in_target_context_manager:\n\u001b[1;32m   2529\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_switch_to_input_mode()\n\u001b[0;32m-> 2530\u001b[0m     encodings \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_one(text\u001b[39m=\u001b[39;49mtext, text_pair\u001b[39m=\u001b[39;49mtext_pair, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mall_kwargs)\n\u001b[1;32m   2531\u001b[0m \u001b[39mif\u001b[39;00m text_target \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m   2532\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_switch_to_target_mode()\n",
      "File \u001b[0;32m~/miniforge3/envs/y3_ads/lib/python3.11/site-packages/transformers/tokenization_utils_base.py:2588\u001b[0m, in \u001b[0;36mPreTrainedTokenizerBase._call_one\u001b[0;34m(self, text, text_pair, add_special_tokens, padding, truncation, max_length, stride, is_split_into_words, pad_to_multiple_of, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, **kwargs)\u001b[0m\n\u001b[1;32m   2585\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m   2587\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m _is_valid_text_input(text):\n\u001b[0;32m-> 2588\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m   2589\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mtext input must of type `str` (single example), `List[str]` (batch or single pretokenized example) \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   2590\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mor `List[List[str]]` (batch of pretokenized examples).\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   2591\u001b[0m     )\n\u001b[1;32m   2593\u001b[0m \u001b[39mif\u001b[39;00m text_pair \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m _is_valid_text_input(text_pair):\n\u001b[1;32m   2594\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m   2595\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mtext input must of type `str` (single example), `List[str]` (batch or single pretokenized example) \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   2596\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mor `List[List[str]]` (batch of pretokenized examples).\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   2597\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: text input must of type `str` (single example), `List[str]` (batch or single pretokenized example) or `List[List[str]]` (batch of pretokenized examples)."
     ]
    }
   ],
   "source": [
    "lang_cls = transformers.pipeline('text-classification',\n",
    "                                 'papluca/xlm-roberta-base-language-detection')\n",
    "batch_size = 20\n",
    "file_path = 'data/yt_w_langs.csv'\n",
    "for batch_i in range(math.ceil(df.shape[0] / batch_size)):\n",
    "  batch = df[batch_size*batch_i : batch_size*(batch_i+1)]\n",
    "  langs = lang_cls(batch['text'].to_list())\n",
    "  for i, lang in enumerate(langs):\n",
    "    batch.at[i, 'lang'] = lang['label']\n",
    "  if batch_i > 0 or os.path.exists(file_path): # if file exists, append\n",
    "    batch.to_csv(file_path, mode='a', header=False, index=False)\n",
    "  else: batch.to_csv(file_path, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "y3_ads",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
